import os
import random
import string
from datetime import datetime
import sys
import platform
import json

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    confusion_matrix,
    classification_report,
    roc_curve,
    auc,
    precision_recall_curve,
)

import tkinter as tk
from tkinter import filedialog, messagebox, ttk


# ==================================================
# CONFIG
# ==================================================
SEED = 42
RESULTS_DIR = "results"
os.makedirs(RESULTS_DIR, exist_ok=True)


# =========================
# 0. UTILITIES
# =========================
def simple_preprocess(text: str) -> str:
    text = text.lower()
    translator = str.maketrans("", "", string.punctuation)
    text = text.translate(translator)
    text = " ".join(text.split())
    return text


def plot_confusion_matrix(cm, labels, title, out_path_png, out_path_csv):
    df_cm = pd.DataFrame(cm, index=labels, columns=labels)
    df_cm.to_csv(out_path_csv, index=True)

    plt.figure()
    plt.imshow(cm, interpolation="nearest")
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(labels))
    plt.xticks(tick_marks, labels, rotation=45, ha="right")
    plt.yticks(tick_marks, labels)
    plt.xlabel("Predetto")
    plt.ylabel("Reale")

    thresh = cm.max() / 2 if cm.max() > 0 else 0
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(
                j,
                i,
                format(cm[i, j], "d"),
                ha="center",
                va="center",
                color="white" if cm[i, j] > thresh else "black",
            )

    plt.tight_layout()
    plt.savefig(out_path_png, dpi=200, bbox_inches="tight")
    plt.close()


def save_environment_info(out_dir: str, seed: int):
    info = {
        "timestamp": datetime.now().isoformat(),
        "python_version": sys.version,
        "platform": platform.platform(),
        "seed": seed,
        "numpy_version": np.__version__,
        "pandas_version": pd.__version__,
    }
    out_path = os.path.join(out_dir, "environment.json")
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(info, f, indent=2, ensure_ascii=False)


def _get_binary_positive_label(series: pd.Series) -> str:
    # assume labels are "pos"/"neg" (but keep generic)
    uniq = sorted(series.unique())
    if "pos" in uniq:
        return "pos"
    return uniq[-1]


def plot_sentiment_curves(y_true, y_prob, out_dir: str):
    # ROC
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    roc_auc = auc(fpr, tpr)
    plt.figure()
    plt.plot(fpr, tpr, label=f"AUC={roc_auc:.3f}")
    plt.plot([0, 1], [0, 1], linestyle="--")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve - Sentiment")
    plt.legend(loc="lower right")
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "sentiment_roc.png"), dpi=200, bbox_inches="tight")
    plt.close()

    # Precision-Recall
    precision, recall, _ = precision_recall_curve(y_true, y_prob)
    pr_auc = auc(recall, precision)
    plt.figure()
    plt.plot(recall, precision, label=f"AUC={pr_auc:.3f}")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title("Precision-Recall Curve - Sentiment")
    plt.legend(loc="lower left")
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "sentiment_pr.png"), dpi=200, bbox_inches="tight")
    plt.close()


# =========================
# 1B. "REALISMO" NEL DATASET SINTETICO (AMBIGUITÀ / MIXED / SINONIMI / RUMORE / TYPO)
# =========================

FILLERS = [
    "onestamente", "in generale", "a dire il vero", "comunque", "diciamo", "sinceramente",
    "per il resto", "tutto sommato", "tra l'altro"
]

SYNONYMS = {
    "pulita": ["in ordine", "linda", "immacolata"],
    "pulizia": ["igiene", "riordino", "sanificazione"],
    "sporco": ["non pulito", "trascurato", "imbrattato"],
    "camera": ["stanza", "camera da letto"],
    "stanza": ["camera", "stanza da letto"],
    "bagno": ["servizi", "toilette"],
    "colazione": ["breakfast", "prima colazione"],
    "ristorante": ["sala ristorante", "cucina"],
    "personale": ["staff", "addetti"],
    "reception": ["front desk", "accoglienza"],
    "check-in": ["check in", "registrazione"],
    "checkin": ["check in", "registrazione"],
    "check-out": ["check out", "saldo"],
    "checkout": ["check out", "saldo"],
    "pagamento": ["saldo", "conto"],
    "lento": ["macchinoso", "troppo lungo"],
    "veloce": ["rapido", "spedito"],
    "gentile": ["cordiale", "disponibile"],
    "ottimo": ["eccellente", "davvero buono"],
    "pessimo": ["scadente", "molto deludente"],
}

DEPT_KEYWORDS = {
    "Housekeeping": ["pulizia", "stanza", "bagno", "asciugamani", "lenzuola", "polvere"],
    "Reception": ["check-in", "check out", "reception", "pagamento", "saldo", "prenotazione"],
    "F&B": ["colazione", "buffet", "ristorante", "cena", "bar", "caffè"]
}

def _apply_synonyms(text: str, p_syn: float = 0.35) -> str:
    words = text.split()
    out = []
    for w in words:
        key = w.lower().strip(".,;:!?()[]\"'")
        if key in SYNONYMS and random.random() < p_syn:
            rep = random.choice(SYNONYMS[key])
            suffix = ""
            if w and w[-1] in ".,;:!?":
                suffix = w[-1]
            out.append(rep + suffix)
        else:
            out.append(w)
    return " ".join(out)

def _inject_fillers(text: str, p_filler: float = 0.20) -> str:
    if random.random() > p_filler:
        return text
    parts = text.split(",")
    if len(parts) >= 2:
        i = random.randrange(len(parts))
        parts[i] = parts[i] + ", " + random.choice(FILLERS)
        return ",".join(parts)
    return text + " " + random.choice(FILLERS)

def _add_typos(text: str, p_typo: float = 0.06) -> str:
    chars = list(text)
    for i in range(1, len(chars) - 2):
        if random.random() < p_typo and chars[i].isalpha() and chars[i+1].isalpha():
            chars[i], chars[i+1] = chars[i+1], chars[i]  # swap di due lettere adiacenti
    return "".join(chars)

def _make_mixed_sentiment(body: str, dept: str, sentiment: str, templates: dict, p_mixed: float = 0.40) -> str:
    """
    Aggiunge una frase di polarità opposta mantenendo l'etichetta originaria.
    Realistico: recensioni con pro + contro.
    """
    if random.random() > p_mixed:
        return body

    dept_templates = templates[dept]
    if sentiment == "pos":
        opposite = random.choice(dept_templates["neg_bodies"])
        tail = " Però " + opposite
    else:
        opposite = random.choice(dept_templates["pos_bodies"])
        tail = " Detto questo, " + opposite

    return body + tail

def _make_ambiguous_dept(body: str, dept: str, p_ambiguous: float = 0.60) -> str:
    if random.random() > p_ambiguous:
        return body

    other_depts = [d for d in DEPT_KEYWORDS.keys() if d != dept]
    other = random.choice(other_depts)

    # 2 keyword intrusive invece di 1
    kws = random.sample(DEPT_KEYWORDS[other], k=2)
    return body + f" (Nota: anche {kws[0]} e {kws[1]} non erano il massimo.)"


# =========================
# 1. GENERATORE DATASET SINTETICO
# =========================
def generate_synthetic_reviews(n_samples: int = 500, random_state: int = 42) -> pd.DataFrame:


    random.seed(random_state)
    np.random.seed(random_state)

    departments = ["Housekeeping", "Reception", "F&B"]
    sentiments = ["pos", "neg"]

    templates = {
        "Housekeeping": {
            "pos_titles": [
                "Camera pulitissima",
                "Ottimo servizio di pulizia",
                "Stanza impeccabile",
                "Pulizia eccellente",
            ],
            "pos_bodies": [
                "La camera era sempre pulita e profumata, asciugamani cambiati ogni giorno.",
                "Servizio di pulizia rapido e accurato, letto rifatto alla perfezione.",
                "Bagno brillante e senza tracce di sporco, complimenti alle cameriere ai piani.",
                "Pulizia della stanza davvero ottima, non ho trovato un granello di polvere.",
            ],
            "neg_titles": [
                "Camera sporca",
                "Pulizia insufficiente",
                "Stanza trascurata",
                "Deluso dalla pulizia",
            ],
            "neg_bodies": [
                "Ho trovato polvere sui mobili e capelli nel bagno, pessima pulizia.",
                "Stanza non pulita bene, asciugamani macchiati e pavimento sporco.",
                "Il bagno aveva cattivo odore e c'erano residui, servizio housekeeping da migliorare.",
                "Molta polvere sotto il letto e lenzuola non fresche, esperienza negativa.",
            ],
        },
        "Reception": {
            "pos_titles": [
                "Check-in veloce",
                "Reception disponibile",
                "Ottima accoglienza",
                "Staff professionale",
            ],
            "pos_bodies": [
                "Check-in rapido e personale gentile, spiegazioni chiare e ottima accoglienza.",
                "Reception molto disponibile, ci hanno aiutato con indicazioni e orari senza problemi.",
                "Pagamento e check out velocissimi, staff cordiale e professionale.",
                "Ottimo servizio in reception, sempre pronti a rispondere alle nostre richieste.",
            ],
            "neg_titles": [
                "Check-in lento",
                "Reception scortese",
                "Problemi al pagamento",
                "Pessima accoglienza",
            ],
            "neg_bodies": [
                "Check-in lunghissimo, fila alla reception e poca organizzazione.",
                "Personale poco gentile, problemi nel gestire il pagamento e il saldo finale.",
                "Check out lento e confuso, hanno sbagliato a registrare la prenotazione.",
                "Accoglienza fredda e poca disponibilità, esperienza negativa con la reception.",
            ],
        },
        "F&B": {
            "pos_titles": [
                "Colazione ottima",
                "Ristorante eccellente",
                "Buffet ricco",
                "Cibo delizioso",
            ],
            "pos_bodies": [
                "Colazione varia e di qualità, ottimo caffè e prodotti freschi.",
                "Ristorante interno davvero buono, piatti gustosi e servizio veloce.",
                "Buffet ricco, croissant caldi e frutta fresca, molto soddisfatto.",
                "Cena ottima, ingredienti di qualità e personale gentile al ristorante.",
            ],
            "neg_titles": [
                "Colazione scarsa",
                "Ristorante deludente",
                "Buffet povero",
                "Cibo pessimo",
            ],
            "neg_bodies": [
                "Colazione povera e prodotti non freschi, poca scelta e caffè pessimo.",
                "Ristorante caro e qualità bassa, piatti freddi e servizio lento.",
                "Buffet quasi vuoto, poche opzioni e rifornimento lento, deludente.",
                "Cena pessima, ingredienti scadenti e personale poco attento al ristorante.",
            ],
        },
    }

    ambiguous_bodies = [
        "La posizione era buona ma ci sono stati piccoli problemi durante il soggiorno.",
        "Nel complesso bene, ma alcuni dettagli potrebbero essere migliorati.",
        "Esperienza discreta, nulla di eccezionale.",
        "Struttura carina, ma ci sono aspetti da curare.",
    ]

    rows = []
    for i in range(1, n_samples + 1):
        dept = random.choice(departments)
        sentiment = random.choice(sentiments)
        
        dept_templates = templates[dept]

        if sentiment == "pos":
            title = random.choice(dept_templates["pos_titles"])
            body = random.choice(dept_templates["pos_bodies"])
        else:
            title = random.choice(dept_templates["neg_titles"])
            body = random.choice(dept_templates["neg_bodies"])

        extra = ""
        if random.random() < 0.40:  # 40% di recensioni con ambiguità
            extra = " " + random.choice(ambiguous_bodies)

        full_body = body + extra

        # ===== Realismo controllato: mixed, ambiguità, sinonimi, rumore, typo =====
        # (Aumenta/diminuisci le probabilità per regolare la difficoltà e ottenere F1 ~ 0.82–0.90)
        full_body = _make_mixed_sentiment(full_body, dept, sentiment, templates, p_mixed=0.40)
        full_body = _make_ambiguous_dept(full_body, dept, p_ambiguous=0.60)
        full_body = _apply_synonyms(full_body, p_syn=0.35)
        full_body = _inject_fillers(full_body, p_filler=0.30)
        full_body = _add_typos(full_body, p_typo=0.07)
        
        dept_label = dept
        if random.random() < 0.06:  # prova 0.05–0.10
            dept_label = random.choice([d for d in departments if d != dept])

        rows.append(
            {
                "id": i,
                "title": title,
                "body": full_body,
                "department": dept_label,   # <-- QUI cambia
                "sentiment": sentiment,
            }
        )

    df = pd.DataFrame(rows)
    return df



# =========================
# 2. PIPELINE ML
# =========================
def train_models(df: pd.DataFrame, out_dir: str, seed: int = 42):
    os.makedirs(out_dir, exist_ok=True)

    df = df.copy()
    df["text"] = (df["title"].fillna("") + " " + df["body"].fillna("")).apply(simple_preprocess)

    # split 80/20 (riproducibile)
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=seed, stratify=df["department"])

    # salva split per riproducibilità
    train_df.to_csv(os.path.join(out_dir, "train_split.csv"), index=False)
    test_df.to_csv(os.path.join(out_dir, "test_split.csv"), index=False)

    split_meta = {
        "seed": seed,
        "test_size": 0.2,
        "stratify": "department",
        "n_train": int(len(train_df)),
        "n_test": int(len(test_df)),
    }
    with open(os.path.join(out_dir, "split_meta.json"), "w", encoding="utf-8") as f:
        json.dump(split_meta, f, indent=2, ensure_ascii=False)

    # vectorizer
    vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_df=0.95)
    X_train = vectorizer.fit_transform(train_df["text"])
    X_test = vectorizer.transform(test_df["text"])

    # -----------------------------
    # 2A) Department classifier
    # -----------------------------
    y_train_dept = train_df["department"]
    y_test_dept = test_df["department"]

    dept_clf = LogisticRegression(max_iter=2000, random_state=seed)
    dept_clf.fit(X_train, y_train_dept)

    y_pred_dept = dept_clf.predict(X_test)

    dept_acc = accuracy_score(y_test_dept, y_pred_dept)
    dept_f1_macro = f1_score(y_test_dept, y_pred_dept, average="macro")

    # report per classe
    dept_report = classification_report(y_test_dept, y_pred_dept, output_dict=True)
    pd.DataFrame(dept_report).transpose().to_csv(os.path.join(out_dir, "dept_classification_report.csv"))

    # confusion matrix
    dept_labels = sorted(df["department"].unique().tolist())
    cm_dept = confusion_matrix(y_test_dept, y_pred_dept, labels=dept_labels)
    plot_confusion_matrix(
        cm_dept,
        labels=dept_labels,
        title="Confusion Matrix - Department",
        out_path_png=os.path.join(out_dir, "dept_confusion_matrix.png"),
        out_path_csv=os.path.join(out_dir, "dept_confusion_matrix.csv"),
    )

    # bar chart F1 per classe dept
    dept_f1_per_class = {k: v["f1-score"] for k, v in dept_report.items() if k in dept_labels}
    plt.figure()
    plt.bar(list(dept_f1_per_class.keys()), list(dept_f1_per_class.values()))
    plt.title("F1-score per classe - Department")
    plt.xlabel("Classe")
    plt.ylabel("F1")
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "dept_f1_per_class.png"), dpi=200, bbox_inches="tight")
    plt.close()

    # -----------------------------
    # 2B) Sentiment classifier
    # -----------------------------
    y_train_sent = train_df["sentiment"]
    y_test_sent = test_df["sentiment"]

    sent_clf = LogisticRegression(max_iter=2000, random_state=seed)
    sent_clf.fit(X_train, y_train_sent)

    y_pred_sent = sent_clf.predict(X_test)

    sent_acc = accuracy_score(y_test_sent, y_pred_sent)
    sent_f1_macro = f1_score(y_test_sent, y_pred_sent, average="macro")

    sent_report = classification_report(y_test_sent, y_pred_sent, output_dict=True)
    pd.DataFrame(sent_report).transpose().to_csv(os.path.join(out_dir, "sent_classification_report.csv"))

    sent_labels = sorted(df["sentiment"].unique().tolist())
    cm_sent = confusion_matrix(y_test_sent, y_pred_sent, labels=sent_labels)
    plot_confusion_matrix(
        cm_sent,
        labels=sent_labels,
        title="Confusion Matrix - Sentiment",
        out_path_png=os.path.join(out_dir, "sent_confusion_matrix.png"),
        out_path_csv=os.path.join(out_dir, "sent_confusion_matrix.csv"),
    )

    # curve ROC/PR (solo se binario e con proba)
    pos_label = _get_binary_positive_label(df["sentiment"])
    if len(sent_labels) == 2 and hasattr(sent_clf, "predict_proba"):
        y_true_bin = (y_test_sent == pos_label).astype(int).values
        y_prob = sent_clf.predict_proba(X_test)[:, sent_labels.index(pos_label)]
        plot_sentiment_curves(y_true_bin, y_prob, out_dir=out_dir)

    # salva metriche riassuntive
    metrics = {
        "department_accuracy": float(dept_acc),
        "department_f1_macro": float(dept_f1_macro),
        "sentiment_accuracy": float(sent_acc),
        "sentiment_f1_macro": float(sent_f1_macro),
    }
    with open(os.path.join(out_dir, "metrics.json"), "w", encoding="utf-8") as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)

    return vectorizer, dept_clf, sent_clf, metrics


# =========================
# 3. DASHBOARD (Tkinter)
# =========================
class HotelReviewApp:
    def __init__(self, root, vectorizer, dept_model, sent_model):
        self.root = root
        self.vectorizer = vectorizer
        self.dept_model = dept_model
        self.sent_model = sent_model

        self.root.title("Hotel Review Routing + Sentiment (ML)")
        self._build_ui()

    def _build_ui(self):
        frm = ttk.Frame(self.root, padding=10)
        frm.grid(row=0, column=0, sticky="nsew")

        ttk.Label(frm, text="Titolo:").grid(row=0, column=0, sticky="w")
        self.title_entry = ttk.Entry(frm, width=80)
        self.title_entry.grid(row=0, column=1, sticky="we", padx=5)

        ttk.Label(frm, text="Testo recensione:").grid(row=1, column=0, sticky="nw")
        self.body_text = tk.Text(frm, width=80, height=10)
        self.body_text.grid(row=1, column=1, sticky="we", padx=5, pady=5)

        btn_frame = ttk.Frame(frm)
        btn_frame.grid(row=2, column=1, sticky="w")

        ttk.Button(btn_frame, text="Predici (singola)", command=self.predict_single).grid(row=0, column=0, padx=5)
        ttk.Button(btn_frame, text="Predici da CSV (batch)", command=self.predict_from_csv).grid(row=0, column=1, padx=5)

        self.result_label = ttk.Label(frm, text="Risultati: -", font=("Arial", 11, "bold"))
        self.result_label.grid(row=3, column=0, columnspan=2, sticky="w", pady=10)

        frm.columnconfigure(1, weight=1)

    def predict_single(self):
        title = self.title_entry.get().strip()
        body = self.body_text.get("1.0", tk.END).strip()
        text = simple_preprocess(f"{title} {body}")

        X = self.vectorizer.transform([text])
        dept_pred = self.dept_model.predict(X)[0]

        sent_pred = self.sent_model.predict(X)[0]
        sent_prob = None
        if hasattr(self.sent_model, "predict_proba"):
            probs = self.sent_model.predict_proba(X)[0]
            classes = list(self.sent_model.classes_)
            # probability of predicted class
            sent_prob = probs[classes.index(sent_pred)]

        if sent_prob is not None:
            self.result_label.config(
                text=f"Risultati: Reparto = {dept_pred} | Sentiment = {sent_pred} (p={sent_prob:.2f})"
            )
        else:
            self.result_label.config(text=f"Risultati: Reparto = {dept_pred} | Sentiment = {sent_pred}")

    def predict_from_csv(self):
        file_path = filedialog.askopenfilename(
            title="Seleziona CSV",
            filetypes=[("CSV files", "*.csv"), ("All files", "*.*")],
        )
        if not file_path:
            return

        try:
            df = pd.read_csv(file_path)
        except Exception as e:
            messagebox.showerror("Errore", f"Impossibile leggere il CSV: {e}")
            return

        if not {"title", "body"}.issubset(df.columns):
            messagebox.showerror("Errore", "Il CSV deve contenere almeno le colonne: title, body")
            return

        df = df.copy()
        df["text"] = (df["title"].fillna("") + " " + df["body"].fillna("")).apply(simple_preprocess)

        X = self.vectorizer.transform(df["text"].tolist())
        df["pred_department"] = self.dept_model.predict(X)
        df["pred_sentiment"] = self.sent_model.predict(X)

        if hasattr(self.sent_model, "predict_proba"):
            probs = self.sent_model.predict_proba(X)
            classes = list(self.sent_model.classes_)
            idx_pos = 0
            # pick probability of predicted class
            pred_idx = [classes.index(s) for s in df["pred_sentiment"].tolist()]
            df["pred_sentiment_prob"] = [float(probs[i, pred_idx[i]]) for i in range(len(pred_idx))]

        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        out_path = os.path.join(RESULTS_DIR, f"batch_predictions_{ts}.csv")
        df.to_csv(out_path, index=False)

        messagebox.showinfo("Completato", f"Predizioni salvate in:\n{out_path}")


# =========================
# MAIN
# =========================
def main():
    random.seed(SEED)
    np.random.seed(SEED)

    save_environment_info(RESULTS_DIR, SEED)

    dataset_path = "reviews_synthetic_V2.csv"
    if not os.path.exists(dataset_path):
        df = generate_synthetic_reviews(n_samples=500, random_state=SEED)
        df.to_csv(dataset_path, index=False)

    df = pd.read_csv(dataset_path)

    vectorizer, dept_model, sent_model, metrics = train_models(df, out_dir=RESULTS_DIR, seed=SEED)

    print("=== METRICHE ===")
    for k, v in metrics.items():
        print(f"{k}: {v:.4f}")

    root = tk.Tk()
    app = HotelReviewApp(root, vectorizer, dept_model, sent_model)
    root.mainloop()


if __name__ == "__main__":
    main()
